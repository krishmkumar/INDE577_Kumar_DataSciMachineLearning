{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Trees (CART) — From Scratch\n",
    "\n",
    "This notebook demonstrates a **Regression Tree** model implemented entirely\n",
    "from scratch using NumPy. The model follows a CART-style approach, recursively\n",
    "partitioning the feature space using impurity-based splits.\n",
    "\n",
    "We apply the model to a real-world housing dataset with a continuous target,\n",
    "highlighting how regression trees capture nonlinear structure without assuming\n",
    "a parametric form.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition Behind Tree-Based Models\n",
    "\n",
    "Tree-based models learn by **recursively partitioning the feature space** into\n",
    "regions that are increasingly homogeneous with respect to the target variable.\n",
    "\n",
    "At each internal node, the algorithm asks a simple question of the form:\n",
    "\n",
    "> “Is feature j less than some threshold t?”\n",
    "\n",
    "Based on the answer, the data are split into two groups, and the process is\n",
    "repeated recursively. Each terminal node (leaf) stores summary statistics of\n",
    "the training samples that fall into that region, which are then used to make\n",
    "predictions.\n",
    "\n",
    "In this implementation, the tree behaves like a **CART-style classification\n",
    "tree**, even though it is named `RegressionTree`. The target values are treated\n",
    "as discrete class labels, and predictions are made by **majority vote within\n",
    "leaf nodes**.\n",
    "\n",
    "This design emphasizes:\n",
    "- Interpretability\n",
    "- Simple decision rules\n",
    "- Clear alignment with ensemble methods such as bagging and random forests\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Formulation\n",
    "\n",
    "### Gini Impurity\n",
    "\n",
    "To evaluate the quality of a split, this implementation uses **Gini impurity**.\n",
    "For a node containing samples from K classes, the Gini impurity is defined as:\n",
    "\n",
    "$$\n",
    "G = 1 - \\sum_{k=1}^{K} p_k^2\n",
    "$$\n",
    "\n",
    "where \\( p_k \\) is the proportion of samples in the node belonging to class \\( k \\).\n",
    "\n",
    "A node is **pure** if all samples belong to the same class, in which case\n",
    "\\( G = 0 \\).\n",
    "\n",
    "---\n",
    "\n",
    "### Split Criterion\n",
    "\n",
    "For a candidate split defined by feature \\( j \\) and threshold \\( t \\), the data\n",
    "are partitioned into:\n",
    "\n",
    "- Left node: \\( X_j < t \\)\n",
    "- Right node: \\( X_j \\ge t \\)\n",
    "\n",
    "The quality of the split is measured by the **weighted Gini impurity**:\n",
    "\n",
    "$$\n",
    "G_{\\text{split}} =\n",
    "\\frac{n_L}{n} G_L + \\frac{n_R}{n} G_R\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( G_L \\), \\( G_R \\) are the Gini impurities of the left and right nodes\n",
    "- \\( n_L \\), \\( n_R \\) are the number of samples in each node\n",
    "- \\( n \\) is the total number of samples at the current node\n",
    "\n",
    "The algorithm selects the feature and threshold that **minimize**\n",
    "\\( G_{\\text{split}} \\).\n",
    "\n",
    "---\n",
    "\n",
    "### Tree Construction\n",
    "\n",
    "The tree is built recursively until one of the following stopping conditions is met:\n",
    "\n",
    "- The maximum depth is reached\n",
    "- All samples in a node belong to the same class\n",
    "- The number of samples is below a minimum threshold\n",
    "\n",
    "When splitting stops, a **leaf node** is created. Each leaf stores the class\n",
    "counts of the samples that fall into that region.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Rule\n",
    "\n",
    "To make a prediction for a new observation, the model:\n",
    "\n",
    "1. Traverses the tree from the root using feature–threshold comparisons\n",
    "2. Reaches a leaf node\n",
    "3. Uses the stored class counts to make a prediction\n",
    "\n",
    "The predicted class is given by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\arg\\max_k \\; n_k\n",
    "$$\n",
    "\n",
    "where \\( n_k \\) is the number of training samples of class \\( k \\) in the leaf.\n",
    "\n",
    "Class probabilities are computed by normalizing the class counts:\n",
    "\n",
    "$$\n",
    "P(y = k) = \\frac{n_k}{\\sum_{j} n_j}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rice2025.supervised_learning.regression_tree import RegressionTree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Housing Prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"housing.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretizing the Target Variable\n",
    "\n",
    "Because the tree implementation performs classification, we convert housing\n",
    "prices into categorical labels representing low, medium, and high price ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "0    6884\n",
      "1    6876\n",
      "2    6880\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target = \"median_house_value\"  # change if needed\n",
    "\n",
    "y_continuous = df[target].values\n",
    "\n",
    "# Discretize into 3 quantile-based classes\n",
    "y = pd.qcut(y_continuous, q=3, labels=[0, 1, 2]).astype(int)\n",
    "\n",
    "X = df.drop(columns=[target]).values\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(pd.Series(y).value_counts().sort_index())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "idx = np.random.permutation(len(X))\n",
    "\n",
    "train_size = int(0.8 * len(X))\n",
    "train_idx, test_idx = idx[:train_size], idx[train_size:]\n",
    "\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the CART-Style Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rice2025.supervised_learning.regression_tree.RegressionTree at 0x177f4af90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = RegressionTree(\n",
    "    max_depth=6,\n",
    "    min_samples_split=20\n",
    ")\n",
    "\n",
    "tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7415\n"
     ]
    }
   ],
   "source": [
    "y_pred = tree.predict(X_test)\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Comparison\n",
    "\n",
    "To contextualize the performance of the tree, we compare it against a simple\n",
    "baseline classifier that always predicts the most frequent class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.3321\n",
      "Tree Accuracy:     0.7415\n"
     ]
    }
   ],
   "source": [
    "# Majority-class baseline\n",
    "majority_class = np.bincount(y_train).argmax()\n",
    "baseline_preds = np.full_like(y_test, majority_class)\n",
    "\n",
    "baseline_acc = np.mean(baseline_preds == y_test)\n",
    "print(f\"Baseline Accuracy: {baseline_acc:.4f}\")\n",
    "print(f\"Tree Accuracy:     {accuracy:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1094,  258,   19],\n",
       "       [ 192, 1057,  131],\n",
       "       [  36,  431,  910]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    cm = np.zeros((len(classes), len(classes)), dtype=int)\n",
    "    for i, c1 in enumerate(classes):\n",
    "        for j, c2 in enumerate(classes):\n",
    "            cm[i, j] = np.sum((y_true == c1) & (y_pred == c2))\n",
    "    return cm\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7979577 , 0.18818381, 0.0138585 ],\n",
       "       [0.13913043, 0.76594203, 0.09492754],\n",
       "       [0.02614379, 0.31299927, 0.66085694]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "cm_norm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized confusion matrix highlights where the model confuses adjacent\n",
    "price categories, which is expected given the discretization.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "Most misclassifications occur between adjacent price categories (low vs medium,\n",
    "medium vs high), which is expected due to discretization. Extreme confusions\n",
    "(low vs high) are relatively rare, indicating that the tree captures broad\n",
    "price structure effectively.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of Tree Depth\n",
    "\n",
    "Tree depth controls the bias–variance tradeoff. We evaluate performance across\n",
    "different depth values to illustrate this behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(1, 11)\n",
    "accs = []\n",
    "\n",
    "for d in depths:\n",
    "    t = RegressionTree(max_depth=d, min_samples_split=20)\n",
    "    t.fit(X_train, y_train)\n",
    "    accs.append(np.mean(t.predict(X_test) == y_test))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(depths, accs, marker=\"o\")\n",
    "plt.xlabel(\"Max Depth\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Tree Depth vs Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Probability Estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = tree.predict_proba(X_test[:5])\n",
    "probs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row represents the estimated probability of a sample belonging to each\n",
    "price category based on the class distribution at the corresponding leaf node.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "The CART-style tree effectively separates housing data into coarse price\n",
    "categories using simple threshold-based rules. While discretization reduces\n",
    "resolution, it allows tree-based classification methods to be applied to\n",
    "continuous economic data.\n",
    "\n",
    "This approach also mirrors how tree classifiers are used as base learners in\n",
    "ensemble methods such as bagging and random forests.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated a CART-style classification tree implemented from\n",
    "scratch and applied to a real housing dataset through target discretization.\n",
    "The example highlights the interpretability and flexibility of tree-based\n",
    "models while maintaining strict alignment between theory and implementation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
